{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c6674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo librerie e metodi utili\n",
    "#(ho importato anche train_test_split per capire se ci fosse cambiamento tra splittare i file manualmente o tramite sklearn )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#importo i dati\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()\n",
    "\n",
    "#definisco le variabili da analizzare e il target - importo le colonne su cui verranno calcolate le distanze\n",
    "x_data = df[['Pclass','SibSp','Parch', 'Fare']] # definisce un punto sull'asse x1...xn che rappresentano le mie colonne X\n",
    "y_data = df[['Survived']] # il target : è la predizione a cui voglio arrivare addestrando i dati X \n",
    "\n",
    "X = np.array(x_data) #inserisco in un array la matrice di dati definita attraverso x_data\n",
    "y = np.array(y_data) #inserisco in un array la matrice di dati definita attraverso x_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Per poter utilizzare KNN bisogna avere un dataset di test ed un dataset da addestrare affinchè si arrivi a predire la classificazione dei punti di test\n",
    "#def data_split_without_SKLearn(X, y, test_size=0.3):\n",
    " #   i = int((1 - test_size) * X.shape[0])  \n",
    "  #  X_test = np.split(X, [i]) #splitto il vettore alla i-esima posizione e prendo da i-esima posizione alla fine\n",
    "   # y_test = np.split(y, [i]) #splitto il vettore alla i-esima posizione e prendo da i-esima posizione alla fine\n",
    "    #return X_test,y_test\n",
    "\n",
    "\n",
    "#come dati da addestrare prendo tutti i dati a disposizione compresi quelli presenti nei dati di test\n",
    "#(immagino quindi che K dovrà essere maggiore o uguale a 5 altrimenti il confronto tra punti avverrà tra punti uguale e questo mi darà una falsa predizione dei dati)\n",
    "X_train = X\n",
    "y_train = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10add90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873134328358209"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Definisco una classe KNN con diversi metodi all'interno\n",
    "class KNN:\n",
    "\n",
    "    #Inizializzazione attributi della classe\n",
    "    def __init__(self, k=5): #scelgo k = 5 attraverso il metodo di convalida incrociata (colonna k-esima = 5, le altre 4 colonne di test)\n",
    "        self.k = k\n",
    "\n",
    "        \n",
    "   # @staticmethod --> per non richiamare self dento la fnz ed evitare l'errore relativo agli argomenti passati in input\n",
    "    def _euclidean_distance(self,p, q):\n",
    "        return np.sqrt(np.sum((p - q) ** 2))\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X #storo le features (X)\n",
    "        self.y_train = y #storo le labels (y)\n",
    "        \n",
    "    #Predizione delle y rispetto alla matrice X utilizzata come dati da confrontare\n",
    "    def predict(self, X):\n",
    "        predictions = [] #preparo una lista vuota da riempire con le predizioni\n",
    "        for p in X: \n",
    "            euc_distances = [self._euclidean_distance(p, q) for q in self.X_train] \n",
    "            #per ogni punto in X calcolo la distanza tra un qualsiasi X e tutte le altre features (X_train)\n",
    "            sorted_k = np.argsort(euc_distances)[:self.k] \n",
    "            #ordino in ordine crescente le distanze tra il primo elemento della lista e il k-esimo elemento \n",
    "            k_nearest = [self.y_train[y] for y in sorted_k]\n",
    "            predictions.append(stats.mode(k_nearest)[0][0])\n",
    "            #stats.mod della libreria scipy è l'equivalente del concetto di most common ovvero passa i valori più frequenti che trova\n",
    "        return np.array(predictions)\n",
    "\n",
    "#creo oggetto cls che richiami i metodi all'interno della classe KNN   \n",
    "cls = KNN()\n",
    "cls.fit(X_train, y_train) #richiamo i miei data set \n",
    "preds = cls.predict(X_test) #utilizzo X_test come dataset per le predizioni relative a y e lancio il metodo della predizione sui data set di test\n",
    "\n",
    "def accuracy(pred , y_test):\n",
    "        accuracy = np.sum(pred == y_test) / len(pred) #prezioni uguali a quelle comparate (y_test) quindi le predizioni corrette/ il numero di predizioni totali\n",
    "        return accuracy\n",
    "\n",
    "accuracy(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ceacc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
